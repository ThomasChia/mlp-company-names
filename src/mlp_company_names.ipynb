{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of names from data\n",
    "data = pd.read_csv('../data/companies_sorted.csv')\n",
    "names = data['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut data to first million names to reduce training time - not looking for the most accurate anyway.\n",
    "names = names[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary of characters and index mapping - to and from integers\n",
    "# Involves making sure all the names are strings (as some are floats) and removing any names with non-alphanumeric characters\n",
    "# (as some of these companies are from other countries and have non-English characters in their names).\n",
    "# Maybe we should limit to US and UK companies only as the names are likely to be more similar and contain English words - extension.\n",
    "names = [str(name) for name in names]\n",
    "pattern = re.compile(r'^[a-zA-Z\\d]+$')\n",
    "filtered_names = [name for name in names if pattern.match(name)]\n",
    "chars = sorted(list(set(''.join(filtered_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {char: i+1 for i, char in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: char for char, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(stoi) == len(chars) + 1, \"Error: Vocabulary size does not match character set size\"\n",
    "assert len(stoi) == len(itos), \"Error: Indexes to characters and characters to indexes do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y datasets from list of company names.\n",
    "# I want two lists of lists, one for x and one for y\n",
    "# x contain the first x letters of each name, each letter will be its own element of a list\n",
    "# y contains the next letter\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for name in filtered_names:\n",
    "    # print(name)\n",
    "    context = [0] * block_size\n",
    "    for char in name + '.':\n",
    "        ix = stoi[char]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # print(''.join([itos[i] for i in context]), '-->', char)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 3, 10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the embeddings for the characters.\n",
    "# The embeddings will be a feature vector of length 10 for each character.\n",
    "# The table of embeddings will be a matrix of size (vocab_size, embedding_size).\n",
    "\n",
    "embedding_size = 10\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "# Createa randn tensor of size (vocab_size, embedding_size) as the embeddings lookup table.\n",
    "C = torch.randn(vocab_size, embedding_size)\n",
    "# Apply these embeddings to the input data by using pytorch indexing.\n",
    "embeddings = C[X]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first hidden layer.\n",
    "# The input of this layer will be each of the characters in the context, input as their feature vectors (embeddings),\n",
    "# the block_size (3) * embedding_size (10) = 30.\n",
    "# The bias will be a vector of size 50, as the hidden layer has 50 outputs.\n",
    "# In the paper, the hidden layer either has 0, 50, or 100 outputs.\n",
    "# To get the activations of the hidden layer, we matrix multiply the inputs by the weights and add the bias, and \n",
    "# then apply the tanh activation function.\n",
    "\n",
    "hidden_size = 50\n",
    "\n",
    "W1 = torch.randn(block_size * embedding_size, hidden_size)\n",
    "b1 = torch.randn(hidden_size)\n",
    "\n",
    "h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 50])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output layer, which will take an input size of the output from the hidden layer (50)\n",
    "# and output a vector of size vocab_size (37).\n",
    "# With these numbers, we then need to normalise them, so we exponentiate them and divide by the sum of the exponentiated values.\n",
    "# This gives us the probabilities of each character being the next character in the sequence.\n",
    "\n",
    "W2 = torch.randn(hidden_size, vocab_size)\n",
    "b2 = torch.randn(vocab_size)\n",
    "\n",
    "logits = h @ W2 + b2\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.9650)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the loss of the model.\n",
    "# The loss is the negative log likelihood of the correct character.\n",
    "# We need to find the next character (Y), and look at the probability the model gives of the actual next character being\n",
    "# the predicted next character by the model.\n",
    "\n",
    "loss = -prob[torch.arange(len(Y)), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1116580, 3]), torch.Size([1116580]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((vocab_size, embedding_size), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((block_size * embedding_size, hidden_size), generator=g, requires_grad=True)\n",
    "b1 = torch.randn(hidden_size, generator=g, requires_grad=True)\n",
    "W2 = torch.randn((hidden_size, vocab_size), generator=g, requires_grad=True)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3807"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = C[X]\n",
    "h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.8153, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "loss.backward()\n",
    "\n",
    "# Update parameters\n",
    "for p in parameters:\n",
    "    p.data += -0.01 * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.939155101776123\n",
      "2.625471830368042\n",
      "2.694211959838867\n",
      "2.7962472438812256\n",
      "3.0440847873687744\n",
      "3.0402674674987793\n",
      "2.792820453643799\n",
      "2.6928231716156006\n",
      "2.659545421600342\n",
      "2.5892138481140137\n",
      "2.4613988399505615\n",
      "2.4509239196777344\n",
      "2.9675216674804688\n",
      "2.6929869651794434\n",
      "2.4946107864379883\n",
      "2.445042133331299\n",
      "2.759065866470337\n",
      "3.015272378921509\n",
      "2.745004892349243\n",
      "2.7951488494873047\n",
      "2.6111488342285156\n",
      "2.535982131958008\n",
      "2.6902029514312744\n",
      "2.431286573410034\n",
      "2.8781919479370117\n",
      "2.922363758087158\n",
      "2.7624025344848633\n",
      "2.805875539779663\n",
      "2.9225165843963623\n",
      "2.4314820766448975\n",
      "2.99627685546875\n",
      "2.5717971324920654\n",
      "2.9652109146118164\n",
      "2.589905261993408\n",
      "2.920271635055542\n",
      "2.7060375213623047\n",
      "2.6206116676330566\n",
      "2.917795181274414\n",
      "2.933218002319336\n",
      "2.361433982849121\n",
      "2.8394644260406494\n",
      "2.673220157623291\n",
      "2.8193938732147217\n",
      "2.693074941635132\n",
      "2.2659153938293457\n",
      "2.9032742977142334\n",
      "2.8549792766571045\n",
      "2.4161155223846436\n",
      "2.4600281715393066\n",
      "2.75777268409729\n",
      "2.773993968963623\n",
      "2.506575107574463\n",
      "2.690840482711792\n",
      "2.6051206588745117\n",
      "2.5806403160095215\n",
      "2.646906852722168\n",
      "3.198324203491211\n",
      "1.9697909355163574\n",
      "2.524233818054199\n",
      "2.843574047088623\n",
      "2.65586519241333\n",
      "2.607677459716797\n",
      "2.5849568843841553\n",
      "2.95916485786438\n",
      "3.065295457839966\n",
      "2.2572708129882812\n",
      "2.8593883514404297\n",
      "2.730163097381592\n",
      "2.431394100189209\n",
      "2.5995609760284424\n",
      "2.728501796722412\n",
      "2.356232166290283\n",
      "2.696932315826416\n",
      "2.7379720211029053\n",
      "2.8810877799987793\n",
      "2.719355344772339\n",
      "2.654071092605591\n",
      "2.743314743041992\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/thomaschia/Code/mlp-company-names/src/mlp_company_names.ipynb Cell 23\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaschia/Code/mlp-company-names/src/mlp_company_names.ipynb#Y103sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thomaschia/Code/mlp-company-names/src/mlp_company_names.ipynb#Y103sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m embeddings \u001b[39m=\u001b[39m C[X[ix]]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thomaschia/Code/mlp-company-names/src/mlp_company_names.ipynb#Y103sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtanh(embeddings\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, block_size \u001b[39m*\u001b[39;49m embedding_size) \u001b[39m@\u001b[39;49m W1 \u001b[39m+\u001b[39;49m b1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaschia/Code/mlp-company-names/src/mlp_company_names.ipynb#Y103sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m logits \u001b[39m=\u001b[39m h \u001b[39m@\u001b[39m W2 \u001b[39m+\u001b[39m b2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thomaschia/Code/mlp-company-names/src/mlp_company_names.ipynb#Y103sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(logits, Y[ix])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "for _ in range(100000):\n",
    "\n",
    "    # Mini batch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    embeddings = C[X[ix]]\n",
    "    h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "\n",
    "    if _ % 1000 == 0:\n",
    "        print(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    for p in parameters:\n",
    "        p.data += -0.01 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2196, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
