{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of names from data\n",
    "data = pd.read_csv('../data/companies_sorted.csv')\n",
    "names = data['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut data to first million names to reduce training time - not looking for the most accurate anyway.\n",
    "names = names[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the vocabulary of characters and index mapping - to and from integers\n",
    "# Involves making sure all the names are strings (as some are floats) and removing any names with non-alphanumeric characters\n",
    "# (as some of these companies are from other countries and have non-English characters in their names).\n",
    "# Maybe we should limit to US and UK companies only as the names are likely to be more similar and contain English words - extension.\n",
    "names = [str(name) for name in names]\n",
    "pattern = re.compile(r'^[a-zA-Z\\d]+$')\n",
    "filtered_names = [name for name in names if pattern.match(name)]\n",
    "chars = sorted(list(set(''.join(filtered_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {char: i+1 for i, char in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: char for char, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(stoi) == len(chars) + 1, \"Error: Vocabulary size does not match character set size\"\n",
    "assert len(stoi) == len(itos), \"Error: Indexes to characters and characters to indexes do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x and y datasets from list of company names.\n",
    "# I want two lists of lists, one for x and one for y\n",
    "# x contain the first x letters of each name, each letter will be its own element of a list\n",
    "# y contains the next letter\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for name in filtered_names:\n",
    "    # print(name)\n",
    "    context = [0] * block_size\n",
    "    for char in name + '.':\n",
    "        ix = stoi[char]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # print(''.join([itos[i] for i in context]), '-->', char)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 3, 10])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the embeddings for the characters.\n",
    "# The embeddings will be a feature vector of length 10 for each character.\n",
    "# The table of embeddings will be a matrix of size (vocab_size, embedding_size).\n",
    "\n",
    "embedding_size = 10\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "# Createa randn tensor of size (vocab_size, embedding_size) as the embeddings lookup table.\n",
    "C = torch.randn(vocab_size, embedding_size)\n",
    "# Apply these embeddings to the input data by using pytorch indexing.\n",
    "embeddings = C[X]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the first hidden layer.\n",
    "# The input of this layer will be each of the characters in the context, input as their feature vectors (embeddings),\n",
    "# the block_size (3) * embedding_size (10) = 30.\n",
    "# The bias will be a vector of size 50, as the hidden layer has 50 outputs.\n",
    "# In the paper, the hidden layer either has 0, 50, or 100 outputs.\n",
    "# To get the activations of the hidden layer, we matrix multiply the inputs by the weights and add the bias, and \n",
    "# then apply the tanh activation function.\n",
    "\n",
    "hidden_size = 50\n",
    "\n",
    "W1 = torch.randn(block_size * embedding_size, hidden_size)\n",
    "b1 = torch.randn(hidden_size)\n",
    "\n",
    "h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 50])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output layer, which will take an input size of the output from the hidden layer (50)\n",
    "# and output a vector of size vocab_size (37).\n",
    "# With these numbers, we then need to normalise them, so we exponentiate them and divide by the sum of the exponentiated values.\n",
    "# This gives us the probabilities of each character being the next character in the sequence.\n",
    "\n",
    "W2 = torch.randn(hidden_size, vocab_size)\n",
    "b2 = torch.randn(vocab_size)\n",
    "\n",
    "logits = h @ W2 + b2\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.9650)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the loss of the model.\n",
    "# The loss is the negative log likelihood of the correct character.\n",
    "# We need to find the next character (Y), and look at the probability the model gives of the actual next character being\n",
    "# the predicted next character by the model.\n",
    "\n",
    "loss = -prob[torch.arange(len(Y)), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1116580, 3]), torch.Size([1116580]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((vocab_size, embedding_size), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((block_size * embedding_size, hidden_size), generator=g, requires_grad=True)\n",
    "b1 = torch.randn(hidden_size, generator=g, requires_grad=True)\n",
    "W2 = torch.randn((hidden_size, vocab_size), generator=g, requires_grad=True)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3807"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100000 --> 16.571256637573242\n",
      "10000/100000 --> 2.5918147563934326\n",
      "20000/100000 --> 2.8205337524414062\n",
      "30000/100000 --> 2.740307569503784\n",
      "40000/100000 --> 2.885132074356079\n",
      "50000/100000 --> 2.818249225616455\n",
      "60000/100000 --> 2.5915589332580566\n",
      "70000/100000 --> 2.6272459030151367\n",
      "80000/100000 --> 2.586326837539673\n",
      "90000/100000 --> 2.3683512210845947\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "stepi = []\n",
    "\n",
    "training_steps = 100000\n",
    "\n",
    "# Forward pass\n",
    "for i in range(training_steps):\n",
    "    stepi.append(i)\n",
    "\n",
    "    # Mini batch\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    embeddings = C[X[ix]]\n",
    "    h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i}/{training_steps} --> {loss.item()}')\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3580, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([892853, 3]) torch.Size([892853])\n",
      "torch.Size([112084, 3]) torch.Size([112084])\n",
      "torch.Size([111643, 3]) torch.Size([111643])\n"
     ]
    }
   ],
   "source": [
    "def get_names(names, block_size=3):\n",
    "    X, Y = [], []\n",
    "    for name in names:\n",
    "        context = [0] * block_size\n",
    "        for char in name + '.':\n",
    "            ix = stoi[char]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(filtered_names)\n",
    "n1 = int(len(filtered_names) * 0.8)\n",
    "n2 = int(len(filtered_names) * 0.9)\n",
    "\n",
    "Xtr, Ytr = get_names(filtered_names[:n1])\n",
    "Xdev, Ydev = get_names(filtered_names[n1:n2])\n",
    "Xte, Yte = get_names(filtered_names[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 10\n",
    "vocab_size = len(stoi)\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7207"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(42)\n",
    "C = torch.randn((vocab_size, embedding_size), generator=g, requires_grad=True)\n",
    "W1 = torch.randn((block_size * embedding_size, hidden_size), generator=g, requires_grad=True)\n",
    "b1 = torch.randn(hidden_size, generator=g, requires_grad=True)\n",
    "W2 = torch.randn((hidden_size, vocab_size), generator=g, requires_grad=True)\n",
    "b2 = torch.randn(vocab_size, generator=g, requires_grad=True)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/200000 --> 18.434898376464844\n",
      "10000/200000 --> 2.885880470275879\n",
      "20000/200000 --> 2.5664989948272705\n",
      "30000/200000 --> 3.15132474899292\n",
      "40000/200000 --> 2.579885959625244\n",
      "50000/200000 --> 2.6074788570404053\n",
      "60000/200000 --> 2.4851465225219727\n",
      "70000/200000 --> 2.9811277389526367\n",
      "80000/200000 --> 2.9497334957122803\n",
      "90000/200000 --> 2.43009090423584\n",
      "100000/200000 --> 2.594923257827759\n",
      "110000/200000 --> 2.6889758110046387\n",
      "120000/200000 --> 2.8581900596618652\n",
      "130000/200000 --> 2.6945888996124268\n",
      "140000/200000 --> 2.3474886417388916\n",
      "150000/200000 --> 3.120798349380493\n",
      "160000/200000 --> 2.6329293251037598\n",
      "170000/200000 --> 2.768908977508545\n",
      "180000/200000 --> 2.889587163925171\n",
      "190000/200000 --> 2.999350070953369\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "stepi = []\n",
    "\n",
    "training_steps = 200000\n",
    "\n",
    "# Forward pass\n",
    "for i in range(training_steps):\n",
    "\n",
    "    # Mini batch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "\n",
    "    # Forward pass\n",
    "    embeddings = C[Xtr[ix]]\n",
    "    h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i}/{training_steps} --> {loss.item()}')\n",
    "\n",
    "    # Backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr* p.grad\n",
    "\n",
    "    # Track stats\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2852be140>]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.554370164871216\n",
      "2.5546374320983887\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def calc_loss(x, y):\n",
    "    embeddings = C[x]\n",
    "    h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(loss.item())\n",
    "\n",
    "calc_loss(Xtr, Ytr)\n",
    "calc_loss(Xdev, Ydev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings=10 <br>\n",
    "hidden_size=50 <br>\n",
    "training=? <br>\n",
    "train = 2.5987 <br>\n",
    "dev = 2.5998 <br>\n",
    "<br>\n",
    "embeddings=10 <br>\n",
    "hidden_size=100 <br>\n",
    "training=200,000 <br>\n",
    "train = 2.5544 <br>\n",
    "dev = 2.5546 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyrosimn.\n",
      "shr.\n",
      "dis.\n",
      "brizia.\n",
      "fcintech.\n",
      "mca.\n",
      "starawsb.\n",
      "auvist.\n",
      "clm.\n",
      "corheletiama.\n",
      "leteloftertek.\n",
      "kcpoision.\n",
      "mindrobenistetegradociono.\n",
      "clrpildhmapio.\n",
      "wpienqucanamtpesian.\n",
      "sbarsmador.\n",
      "inga2dentormariz.\n",
      "gede.\n",
      "jsspruse.\n",
      "dol.\n"
     ]
    }
   ],
   "source": [
    "g_sample = torch.Generator().manual_seed(420)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        embeddings = C[torch.tensor([context])]\n",
    "        h = torch.tanh(embeddings.view(-1, block_size * embedding_size) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs[0], 1, generator=g_sample).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join([itos[i] for i in out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
